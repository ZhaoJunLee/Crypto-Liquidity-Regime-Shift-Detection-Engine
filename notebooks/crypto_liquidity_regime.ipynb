#!/usr/bin/env python
# coding: utf-8

# In[2]:


import zipfile
import glob
import os
import duckdb
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches


# In[14]:

# 1️⃣ Data Ingestion

# ENTER YOUR INPUT HERE

# =========================
# MARKET STRUCTURE
# =========================
SYMBOL = "AXS"
BAR_INTERVAL_MIN = 5
BARS_PER_DAY = 24 * 60 // BAR_INTERVAL_MIN  # 288


# =========================
# TEMPORAL WINDOWS
# =========================
FWD_RETURN_HORIZON = BARS_PER_DAY          # 1-day forward return
Z_WINDOW = BARS_PER_DAY                   # rolling normalization window
DENSITY_WINDOW = 12                       # ~1 hour (5m bars)
VOL_PRESSURE_WINDOW = BARS_PER_DAY        # cumulative volume pressure window


# =========================
# SIGNAL THRESHOLDS
# =========================
IMBALANCE_DENSITY_THRESHOLD = 0.5         # 50% of recent bars show imbalance
Z_SCORE_THRESHOLD = 1.0                   # statistical significance cutoff


# In[15]:


# run only you need to unzip files into CSV

raw_zip_dir = f"../data/raw/{SYMBOL}"          # All raw .zip files here
unzipped_dir = f"../data/raw/{SYMBOL}/unzipped"  # Where CSVs will be extracted
os.makedirs(unzipped_dir, exist_ok=True)

for zip_file in glob.glob(f"{raw_zip_dir}/*.zip"):
    with zipfile.ZipFile(zip_file, 'r') as z:
        z.extractall(unzipped_dir)

print(f"✅ Unzipped files to {unzipped_dir}")


# In[5]:


# Run only you need to convert CSV to Parquet (partitioned by trade_date)

con = duckdb.connect()
processed_path = f"../data/processed/{SYMBOL}/aggTrades"  # Single folder for Parquet
os.makedirs(processed_path, exist_ok=True)

csv_pattern = f"{unzipped_dir}/*.csv"


con.execute(f"""
COPY (
    SELECT
        column0::BIGINT AS agg_trade_id
        , column1::DOUBLE AS price
        , column2::DOUBLE AS quantity
        , column3::BIGINT AS first_trade_id
        , column4::BIGINT AS last_trade_id
        , TO_TIMESTAMP(column5::BIGINT / 1000000) AS event_time
        , CAST(TO_TIMESTAMP(column5::BIGINT / 1000000) AS DATE) AS trade_date
        , column6::BOOLEAN AS is_buyer_maker
        
    FROM read_csv(
        '{csv_pattern}'
        , HEADER=FALSE
        , DELIM=','
        , AUTO_DETECT=FALSE
        , COLUMNS={{
            'column0': 'BIGINT'
            , 'column1': 'DOUBLE'
            , 'column2': 'DOUBLE'
            , 'column3': 'BIGINT'
            , 'column4': 'BIGINT'
            , 'column5': 'BIGINT'
            , 'column6': 'BOOLEAN'
            , 'column7': 'BOOLEAN'
        }}
        , STRICT_MODE=FALSE
    )
)
TO '{processed_path}' (
    FORMAT PARQUET
    , PARTITION_BY (trade_date)
    , OVERWRITE_OR_IGNORE
);
""")

print("✅ Converted CSVs to partitioned Parquet")


# 2️⃣ OHLCV Bar Construction
# In[6]:


# Obtain basic data from the Parquet files
# Get trade date/time and OHCLV

def build_ohlcv_bars(
    bar_interval: str = "5 minutes",
    processed_base_path: str = f"../data/processed/{SYMBOL}/aggTrades",
):
    """
    Build OHLCV bars with buy/sell volume from partitioned aggTrades Parquet files.
    Assumes ONE symbol only.
    """

    # 1️⃣ Validate parquet existence (glob-aware)
    parquet_files = glob.glob(
        os.path.join(processed_base_path, "**", "*.parquet"),
        recursive=True
    )

    if len(parquet_files) == 0:
        raise FileNotFoundError(
            f"No Parquet files found under {processed_base_path}"
        )

    print(f"✅ Found {len(parquet_files)} parquet files")

    # 2️⃣ DuckDB query
    con = duckdb.connect()

    query = f"""
        WITH base_trades AS (
            SELECT
                trade_date
                , time_bucket(INTERVAL '{bar_interval}', event_time) AS bar_start
                , price
                , quantity
                , is_buyer_maker
                , event_time
            FROM read_parquet('{processed_base_path}/**/*.parquet')
            WHERE trade_date BETWEEN DATE '2025-01-01' AND DATE '2026-01-22'
        )

        SELECT
            trade_date
            , bar_start
            , arg_min(price, event_time) AS open
            , max(price) AS high
            , min(price) AS low
            , arg_max(price, event_time) AS close
            , sum(quantity) AS volume
            , sum(CASE WHEN is_buyer_maker = FALSE THEN quantity ELSE 0 END) AS buy_volume
            , sum(CASE WHEN is_buyer_maker = TRUE  THEN quantity ELSE 0 END) AS sell_volume
        FROM base_trades
        GROUP BY trade_date, bar_start
        ORDER BY bar_start;    
    """

    bars = con.execute(query).df()
    float_cols = [
    'open','high','low','close','volume',
    'buy_volume','sell_volume'
    ]
    bars[float_cols] = bars[float_cols].astype('float32')
    return bars

bars = build_ohlcv_bars(bar_interval="5 minutes")


# 3️⃣ Liquidity Feature Engineering
# In[7]:


# Calculate Senior-level Liquidity Features (returns/ imbalance/ burst_volume/ illiquidty)
# We filter out any potential negative or error in volume.
# range_pct= total price movement in percentage
bars = bars[bars['volume'] > 0].copy()
bars['returns'] = bars['close'].pct_change()
bars['range_pct'] = (bars['high'] - bars['low']) / bars['open']

# 1. Buy/Sell Imbalance (The 'Pressure' Signal)
# Range: -1 (Max Selling) to +1 (Max Buying)
bars['imbalance'] = (bars['buy_volume'] - bars['sell_volume']) / bars['volume']

# 2. Relative Volume (The 'Burst' Signal)
# Compares current volume to the rolling 12-bar (1 hour) average
bars['vol_ma_1h'] = bars['volume'].rolling(window=DENSITY_WINDOW).mean()
bars['vol_burst'] = bars['volume'] / bars['vol_ma_1h']

# 3. Liquidity Efficiency (Amihud Proxy, price movement relative to liquidity)
# High value = Price moves a lot on low volume (Fragile Liquidity)
bars['illiquidity'] = bars['range_pct'].abs() / (bars['volume'] / 1e6)

print(bars[['bar_start', 'close', 'imbalance', 'vol_burst', 'illiquidity']].tail(10))


# In[8]:


# Visualize the Liquidity Features
import matplotlib.pyplot as plt
fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)

axes[0].plot(bars['bar_start'], bars['close'])
axes[0].set_title("Price")

axes[1].plot(bars['bar_start'], bars['imbalance'])
axes[1].axhline(0, linestyle='--')
axes[1].set_title("Buy/Sell Imbalance")

axes[2].plot(bars['bar_start'], bars['vol_burst'])
axes[2].axhline(1, linestyle='--')
axes[2].set_title("Relative Volume")

axes[3].plot(bars['bar_start'], bars['illiquidity'])
axes[3].set_title("Illiquidity (Amihud proxy)")


# 4️⃣ Regime Detection & Visualization
# In[9]:


# We are defining a potential buying or selling event based on cumulative liquidity pressure.
# Price moves based on cumulative liquidity pressure.
# We calcaulte forward return over N bars

plt.close('all')

bars['fwd_return_1d'] = bars['close'].shift(-BARS_PER_DAY) / bars['close'] - 1


# In[10]:


# We looked for buy-sell imbalance which is higher than average z-scre of 1.0.
imb_mean = bars['imbalance'].rolling(BARS_PER_DAY).mean()
imb_std  = bars['imbalance'].rolling(BARS_PER_DAY).std()
bars['imb_z'] = (bars['imbalance'] - imb_mean) / imb_std

# Identify the direction of imbalance, defined them as positive or negative
bars['imbalance_pos'] = bars['imb_z'] > Z_SCORE_THRESHOLD     # strong buy bar
bars['imbalance_neg'] = bars['imb_z'] < -Z_SCORE_THRESHOLD    # strong sell bar

# Calculate the density of imbalance (from 0 to 1.0)
bars['buy_imbalance_density'] = (
    bars['imbalance_pos']
    .rolling(DENSITY_WINDOW)
    .mean()
)

bars['sell_imbalance_density'] = (
    bars['imbalance_neg']
    .rolling(DENSITY_WINDOW)
    .mean()
)

#Cumulative cumulative imbalance pressure (magnitude) with its z-score
bars['imbalance_pressure'] = (
    bars['imbalance']
    .rolling(DENSITY_WINDOW)
    .sum()
)

bars['imbalance_pressure_z'] = (
    bars['imbalance_pressure']
    - bars['imbalance_pressure'].rolling(Z_WINDOW).mean()
) / bars['imbalance_pressure'].rolling(Z_WINDOW).std()

# Determine the magnitude of imbalance for visualization later
bars['pressure_strength'] = np.abs(bars['imbalance_pressure_z'])


# In[11]:


# cumulative volume pressure
# bars['vol_pressure']= we only take relative volume that is higher than 1
bars['vol_pressure'] = (
    (bars['vol_burst'] - 1)
    .clip(lower=0)
    .rolling(VOL_PRESSURE_WINDOW)
    .sum()
)

bars['vol_pressure_z'] = (
    bars['vol_pressure'] -
    bars['vol_pressure'].rolling(Z_WINDOW).mean()
) / bars['vol_pressure'].rolling(Z_WINDOW).std()


# In[12]:


'''
Pressure event is defined as:
50% of buying or selling imbalance pressure is above average with a z-score of 1.0
at high volume pressure with a a z-score of 1.0 again.

This is designed to remove "fake outs" (low volume price moves) or "absorptions" (high volume but no directional imbalance).

Return pressure signal as Buy or Sell.
'''  

bars['buy_pressure_event'] = (
    (bars['buy_imbalance_density'] >= IMBALANCE_DENSITY_THRESHOLD) &
    (bars['vol_pressure_z'] > Z_SCORE_THRESHOLD)
)

bars['sell_pressure_event'] = (
    (bars['sell_imbalance_density'] >= IMBALANCE_DENSITY_THRESHOLD) &
    (bars['vol_pressure_z'] > Z_SCORE_THRESHOLD)
)

bars['pressure_signal'] = np.select(
    condlist=[
        bars['buy_pressure_event'],
        bars['sell_pressure_event']
    ],
    choicelist=['buy', 'sell'],
    default='none'
)


# In[13]:


# Visualize the potential buying and selling events

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

plt.figure(figsize=(14, 5))

# Price
plt.plot(
    bars['bar_start'],
    bars['close'],
    color='black',
    linewidth=1,
    label='Close'
)

# BUY pressure (green → yellow = stronger)
buy = bars['pressure_signal'] == 'buy'
plt.scatter(
    bars.loc[buy, 'bar_start'],
    bars.loc[buy, 'close'],
    c=bars.loc[buy, 'pressure_strength'],
    cmap='Greens',
    s=80,
    alpha=0.8,
    label='Buy Pressure'
)

# SELL pressure (orange → red = stronger)
sell = bars['pressure_signal'] == 'sell'
plt.scatter(
    bars.loc[sell, 'bar_start'],
    bars.loc[sell, 'close'],
    c=bars.loc[sell, 'pressure_strength'],
    cmap='Reds',
    s=80,
    alpha=0.8,
    label='Sell Pressure'
)

plt.title(f"{SYMBOL} Price with Directional Liquidity Pressure (Strength-Mapped)")
plt.legend()
plt.tight_layout()
plt.show()
plt.savefig('figures/example.png')

# In[ ]:

